{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PassivelyIronic/umwdm_OCTMNIST_CNV_prediction/blob/main/umwdm_OCTMNIST_CNV_vs_NORMAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unxKsGXaxAgT"
      },
      "source": [
        "OCTMNIST - TRANSFER LEARNING: BINARY CLASSIFICATION (CNV vs NORMAL)\n",
        "\n",
        "CEL PROJEKTU:\n",
        "Klasyfikacja binarnych obrazów OCT (Optical Coherence Tomography) siatkówki\n",
        "w celu automatycznej diagnostyki choroby CNV (Choroidal Neovascularization)\n",
        "vs zdrowej siatkówki (NORMAL). Projekt wykorzystuje transfer learning (ResNet18)\n",
        "do rozwiązania problemu diagnostycznego z ograniczoną ilością danych medycznych.\n",
        "\n",
        "ZAKRES PROJEKTU:\n",
        "1. Eksploracyjna analiza danych (EDA) - rozkład klas, wizualizacje\n",
        "2. Preprocessing obrazów - CLAHE, Gaussian Blur, normalizacja\n",
        "3. Balansowanie klas - WeightedRandomSampler\n",
        "4. Transfer Learning - ResNet18 z pretrenowanymi wagami ImageNet\n",
        "5. Tuning hiperparametrów - Optuna (15 trials)\n",
        "6. Trening i walidacja modelu\n",
        "7. Ewaluacja - confusion matrix, ROC curve, precision-recall curve\n",
        "8. Zaawansowana wyjaśnialność - Grad-CAM, Saliency Maps, Integrated Gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iq9xN2Cjw-3y"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BLOK 0: SETUP I INSTALACJA\n",
        "# ============================================================================\n",
        "\n",
        "!pip install -q medmnist optuna torch torchvision matplotlib seaborn\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler, Subset\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "from medmnist import OCTMNIST, INFO\n",
        "from sklearn.metrics import (classification_report, confusion_matrix,\n",
        "                             roc_curve, auc, precision_recall_curve,\n",
        "                             precision_score, recall_score, f1_score)\n",
        "import optuna\n",
        "\n",
        "# Konfiguracja\n",
        "CHECKPOINT_DIR = 'checkpoints'\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTQViMsbxFZ-"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CHECKPOINTy\n",
        "# ============================================================================\n",
        "\n",
        "def save_checkpoint(name, data):\n",
        "    \"\"\"Zapisuje checkpoint do pliku\"\"\"\n",
        "    path = os.path.join(CHECKPOINT_DIR, f'{name}.pkl')\n",
        "    with open(path, 'wb') as f:\n",
        "        pickle.dump(data, f)\n",
        "    print(f\"Checkpoint saved: {name}\")\n",
        "\n",
        "def load_checkpoint(name):\n",
        "    \"\"\"Wczytuje checkpoint z pliku\"\"\"\n",
        "    path = os.path.join(CHECKPOINT_DIR, f'{name}.pkl')\n",
        "    if os.path.exists(path):\n",
        "        with open(path, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "        print(f\"Checkpoint loaded: {name}\")\n",
        "        return data\n",
        "    return None\n",
        "\n",
        "def checkpoint_exists(name):\n",
        "    \"\"\"Sprawdza czy checkpoint istnieje\"\"\"\n",
        "    path = os.path.join(CHECKPOINT_DIR, f'{name}.pkl')\n",
        "    return os.path.exists(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXqFPN6VxSlC"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BLOK 1: WCZYTYWANIE I FILTROWANIE DANYCH\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BLOK 1: LOADING DATA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Próba wczytania z checkpointu\n",
        "datasets_checkpoint = load_checkpoint('datasets')\n",
        "\n",
        "if datasets_checkpoint:\n",
        "    train_dataset = datasets_checkpoint['train']\n",
        "    val_dataset = datasets_checkpoint['val']\n",
        "    test_dataset = datasets_checkpoint['test']\n",
        "    train_labels = datasets_checkpoint['train_labels']\n",
        "else:\n",
        "    train_dataset = OCTMNIST(split='train', download=True, transform=None)\n",
        "    val_dataset = OCTMNIST(split='val', download=True, transform=None)\n",
        "    test_dataset = OCTMNIST(split='test', download=True, transform=None)\n",
        "\n",
        "    # Filtrowanie do klas binarnych (CNV=0, NORMAL=3)\n",
        "    def filter_to_binary(dataset, keep_classes=[0, 3]):\n",
        "        indices = [idx for idx, (_, label) in enumerate(dataset) if label in keep_classes]\n",
        "        return Subset(dataset, indices)\n",
        "\n",
        "    train_dataset = filter_to_binary(train_dataset)\n",
        "    val_dataset = filter_to_binary(val_dataset)\n",
        "    test_dataset = filter_to_binary(test_dataset)\n",
        "\n",
        "    train_labels = np.array([train_dataset.dataset[idx][1] for idx in train_dataset.indices])\n",
        "\n",
        "    save_checkpoint('datasets', {\n",
        "        'train': train_dataset,\n",
        "        'val': val_dataset,\n",
        "        'test': test_dataset,\n",
        "        'train_labels': train_labels\n",
        "    })\n",
        "\n",
        "print(f\"Train: {len(train_dataset)} | Val: {len(val_dataset)} | Test: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqUlpOS9xgUh"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BLOK 2A: ANALIZA ROZKŁADU KLAS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BLOK 2A: CLASS DISTRIBUTION ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "unique, counts = np.unique(train_labels, return_counts=True)\n",
        "imbalance_ratio = np.max(counts) / np.min(counts)\n",
        "\n",
        "print(f\"CNV: {counts[0]:,} samples ({counts[0]/len(train_labels)*100:.1f}%)\")\n",
        "print(f\"NORMAL: {counts[1]:,} samples ({counts[1]/len(train_labels)*100:.1f}%)\")\n",
        "print(f\"Imbalance ratio: {imbalance_ratio:.2f}:1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lxulr5eCxjVU"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BLOK 2B: WIZUALIZACJA ROZKŁADU\n",
        "# ============================================================================\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = sns.barplot(x=unique.flatten(), y=counts, palette='viridis')\n",
        "plt.title(\"Class Distribution (CNV vs NORMAL)\", fontsize=14, weight='bold')\n",
        "plt.xlabel(\"Class\", fontsize=12)\n",
        "plt.ylabel(\"Samples\", fontsize=12)\n",
        "\n",
        "for i, bar in enumerate(bars.patches):\n",
        "    height = bar.get_height()\n",
        "    bars.text(bar.get_x() + bar.get_width()/2., height,\n",
        "             f'{int(height):,}',\n",
        "             ha='center', va='bottom', fontsize=10, weight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOzNyKsux-rT"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BLOK 3: PRZYKŁADOWE OBRAZY\n",
        "# ============================================================================\n",
        "\n",
        "def show_samples(dataset, samples_per_class=5):\n",
        "    classes = [0, 3]\n",
        "    class_names = ['CNV', 'NORMAL']\n",
        "\n",
        "    fig, axes = plt.subplots(2, samples_per_class, figsize=(samples_per_class*2.5, 10))\n",
        "    fig.suptitle(\"Sample OCT Images\", fontsize=16, weight='bold')\n",
        "\n",
        "    for i, (cls, name) in enumerate(zip(classes, class_names)):\n",
        "        indices = [idx for idx, (_, label) in enumerate(dataset) if label == cls]\n",
        "        selected = np.random.choice(indices, min(samples_per_class, len(indices)), replace=False)\n",
        "\n",
        "        for j, idx in enumerate(selected):\n",
        "            img, _ = dataset[idx]\n",
        "            axes[i, j].imshow(img, cmap='gray')\n",
        "            axes[i, j].axis('off')\n",
        "            if j == 0:\n",
        "                axes[i, j].set_ylabel(f\"{name}\", rotation=0, labelpad=40,\n",
        "                                     fontsize=12, weight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_samples(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-fYXCfcyKYz"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BLOK 4: PREPROCESSING CLASSES\n",
        "# ============================================================================\n",
        "\n",
        "class CLAHETransform:\n",
        "    def __init__(self, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
        "        self.clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
        "\n",
        "    def __call__(self, img):\n",
        "        np_img = np.array(img)\n",
        "        if len(np_img.shape) == 3:\n",
        "            np_img = cv2.cvtColor(np_img, cv2.COLOR_RGB2GRAY)\n",
        "        return Image.fromarray(self.clahe.apply(np_img))\n",
        "\n",
        "class GaussianDenoise:\n",
        "    def __init__(self, ksize=3):\n",
        "        self.ksize = ksize\n",
        "\n",
        "    def __call__(self, img):\n",
        "        np_img = np.array(img)\n",
        "        blurred = cv2.GaussianBlur(np_img, (self.ksize, self.ksize), 0)\n",
        "        return Image.fromarray(blurred)\n",
        "\n",
        "# Pipeline\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    CLAHETransform(clip_limit=2.0, tile_grid_size=(8, 8)),\n",
        "    GaussianDenoise(ksize=3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset.dataset.transform = transform\n",
        "val_dataset.dataset.transform = transform\n",
        "test_dataset.dataset.transform = transform\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BLOK 4: PREPROCESSING APPLIED\")\n",
        "print(\"=\"*60)\n",
        "print(\"Resize -> 256x256\")\n",
        "print(\"CLAHE -> contrast enhancement\")\n",
        "print(\"Gaussian Blur -> noise reduction\")\n",
        "print(\"Normalization -> [-1, 1]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LdD6hFcyUHz"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BLOK 5: BALANSOWANIE KLAS I DATALOADER\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BLOK 5: CLASS BALANCING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "class_mapping = {0: 0, 3: 1}\n",
        "targets = torch.tensor([int(train_dataset.dataset[idx][1]) for idx in train_dataset.indices])\n",
        "targets_mapped = torch.tensor([class_mapping[int(t)] for t in targets])\n",
        "\n",
        "class_weights = 1.0 / torch.tensor([counts[0], counts[1]], dtype=torch.float)\n",
        "sample_weights = class_weights[targets_mapped]\n",
        "\n",
        "sampler = WeightedRandomSampler(\n",
        "    weights=sample_weights,\n",
        "    num_samples=len(sample_weights),\n",
        "    replacement=True\n",
        ")\n",
        "\n",
        "# DataLoader\n",
        "BATCH_SIZE = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f\"WeightedRandomSampler configured\")\n",
        "print(f\"DataLoaders ready (batch_size={BATCH_SIZE})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUP-PRj9yepw"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BLOK 6: MODEL DEFINITION\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BLOK 6: MODEL ARCHITECTURE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "class TransferLearningModel(nn.Module):\n",
        "    def __init__(self, num_classes=2, freeze_backbone=True, dropout=0.5):\n",
        "        super(TransferLearningModel, self).__init__()\n",
        "        self.backbone = models.resnet18(pretrained=True)\n",
        "\n",
        "        if freeze_backbone:\n",
        "            for param in self.backbone.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        self.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2,\n",
        "                                       padding=3, bias=False)\n",
        "\n",
        "        num_features = self.backbone.fc.in_features\n",
        "        self.backbone.fc = nn.Sequential(\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(num_features, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "print(\"ResNet18 Transfer Learning model defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qG7BjZTOyu99"
      },
      "outputs": [],
      "source": [
        "# Usuń checkpointy przed blokiem Optuna\n",
        "!rm -f checkpoints/datasets.pkl\n",
        "!rm -f optuna_study.db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKjW9ynGy0dd"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BLOK 7: HYPERPARAMETER TUNING\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BLOK 7: HYPERPARAMETER TUNING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# False dla wgrania z checkpointu\n",
        "FORCE_NEW_TUNING = True\n",
        "\n",
        "def map_labels(labels):\n",
        "    \"\"\"Mapowanie i spłaszczanie etykiet do formatu 1D\"\"\"\n",
        "    mapped = torch.tensor([class_mapping[int(l)] for l in labels.cpu()], dtype=torch.long)\n",
        "    return mapped.to(labels.device).view(-1)\n",
        "\n",
        "def nuclear_clean_optuna():\n",
        "    \"\"\"Wyczyszczenie plików Optuna\"\"\"\n",
        "    print(\"\\nCleaning Optuna files...\")\n",
        "\n",
        "    removed_count = 0\n",
        "\n",
        "    # pliki .db\n",
        "    db_patterns = ['optuna*.db*', '*.db-journal', '*.db-wal', '*.db-shm']\n",
        "    for pattern in db_patterns:\n",
        "        for file in glob.glob(pattern):\n",
        "            try:\n",
        "                os.remove(file)\n",
        "                print(f\"  Removed: {file}\")\n",
        "                removed_count += 1\n",
        "            except Exception as e:\n",
        "                print(f\"  Could not remove {file}: {e}\")\n",
        "\n",
        "    # Checkpoint pickle\n",
        "    checkpoint_path = os.path.join(CHECKPOINT_DIR, 'optuna_study.pkl')\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        try:\n",
        "            os.remove(checkpoint_path)\n",
        "            print(f\"  Removed: optuna_study.pkl\")\n",
        "            removed_count += 1\n",
        "        except Exception as e:\n",
        "            print(f\"  Could not remove checkpoint: {e}\")\n",
        "\n",
        "    print(f\"  Cleanup complete ({removed_count} items)\\n\")\n",
        "\n",
        "def objective(trial):\n",
        "    \"\"\"Funkcja objective dla Optuna\"\"\"\n",
        "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
        "    dropout = trial.suggest_float('dropout', 0.3, 0.7)\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'SGD'])\n",
        "\n",
        "    model_trial = TransferLearningModel(\n",
        "        num_classes=2,\n",
        "        freeze_backbone=True,\n",
        "        dropout=dropout\n",
        "    ).to(device)\n",
        "\n",
        "    if optimizer_name == 'Adam':\n",
        "        optimizer = optim.Adam(\n",
        "            filter(lambda p: p.requires_grad, model_trial.parameters()),\n",
        "            lr=lr\n",
        "        )\n",
        "    else:\n",
        "        optimizer = optim.SGD(\n",
        "            filter(lambda p: p.requires_grad, model_trial.parameters()),\n",
        "            lr=lr,\n",
        "            momentum=0.9\n",
        "        )\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    max_batches = 20\n",
        "\n",
        "    for epoch in range(3):\n",
        "        model_trial.train()\n",
        "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "            if batch_idx >= max_batches:\n",
        "                break\n",
        "\n",
        "            images = images.to(device)\n",
        "            labels = map_labels(labels).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model_trial(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Walidacja\n",
        "    model_trial.eval()\n",
        "    correct, total = 0, 0\n",
        "    max_val_batches = 10\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, labels) in enumerate(val_loader):\n",
        "            if batch_idx >= max_val_batches:\n",
        "                break\n",
        "\n",
        "            images = images.to(device)\n",
        "            labels = map_labels(labels).to(device)\n",
        "\n",
        "            outputs = model_trial(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total if total > 0 else 0.0\n",
        "\n",
        "    print(f\"  Trial {trial.number:2d}: lr={lr:.2e}, dropout={dropout:.2f}, \"\n",
        "          f\"{optimizer_name:4s} -> acc={accuracy:.4f}\")\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "if FORCE_NEW_TUNING:\n",
        "    print(\"FORCE_NEW_TUNING = True\")\n",
        "    nuclear_clean_optuna()\n",
        "\n",
        "optuna_checkpoint = load_checkpoint('optuna_study')\n",
        "\n",
        "if optuna_checkpoint and not FORCE_NEW_TUNING:\n",
        "    print(\"Loaded existing Optuna study from checkpoint\")\n",
        "    study = optuna_checkpoint['study']\n",
        "    best_params = study.best_params\n",
        "    print(f\"\\nUsing cached results ({len(study.trials)} trials)\")\n",
        "\n",
        "else:\n",
        "    print(\"Creating NEW Optuna study...\")\n",
        "    print(\"   Storage: IN-MEMORY (no database files)\")\n",
        "    print(\"   Trials: 15\")\n",
        "    print(\"   Each trial: 3 epochs x 20 batches\\n\")\n",
        "\n",
        "    study = optuna.create_study(\n",
        "        study_name='octmnist_binary',\n",
        "        storage=None,\n",
        "        direction='maximize'\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        print(\"=\"*60)\n",
        "        study.optimize(objective, n_trials=15, show_progress_bar=True)\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        best_params = study.best_params\n",
        "\n",
        "        save_checkpoint('optuna_study', {\n",
        "            'study': study,\n",
        "            'best_params': best_params\n",
        "        })\n",
        "\n",
        "        print(\"\\nTuning complete and saved to checkpoint\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError during optimization: {e}\")\n",
        "        print(\"   Using default hyperparameters as fallback...\")\n",
        "        best_params = {\n",
        "            'lr': 0.001,\n",
        "            'dropout': 0.5,\n",
        "            'optimizer': 'Adam'\n",
        "        }\n",
        "        study = optuna.create_study(direction='maximize', storage=None)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BEST HYPERPARAMETERS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"  Learning Rate:  {best_params['lr']:.6f}\")\n",
        "print(f\"  Dropout:        {best_params['dropout']:.3f}\")\n",
        "print(f\"  Optimizer:      {best_params['optimizer']}\")\n",
        "\n",
        "if hasattr(study, 'best_value'):\n",
        "    print(f\"  Best Val Acc:   {study.best_value:.4f}\")\n",
        "    print(f\"  Total Trials:   {len(study.trials)}\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "\n",
        "db_files = glob.glob('optuna*.db*')\n",
        "if db_files:\n",
        "    print(f\"\\nWARNING: Found database files: {db_files}\")\n",
        "    print(\"   These should not exist with in-memory storage!\")\n",
        "else:\n",
        "    print(\"\\nVerified: No database files created (in-memory only)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USU7POemzWCw"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BLOK 8: WIZUALIZACJA OPTUNA\n",
        "# ============================================================================\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "trials_df = study.trials_dataframe()\n",
        "axes[0].plot(trials_df['number'], trials_df['value'], marker='o', linewidth=2,\n",
        "             markersize=6, color='steelblue')\n",
        "axes[0].axhline(y=study.best_value, color='red', linestyle='--', linewidth=2,\n",
        "                label=f'Best: {study.best_value:.4f}')\n",
        "axes[0].set_xlabel('Trial', fontsize=12)\n",
        "axes[0].set_ylabel('Validation Accuracy', fontsize=12)\n",
        "axes[0].set_title('Optimization History', fontsize=14, weight='bold')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "importance = optuna.importance.get_param_importances(study)\n",
        "axes[1].barh(list(importance.keys()), list(importance.values()),\n",
        "             color='steelblue', edgecolor='black')\n",
        "axes[1].set_xlabel('Importance', fontsize=12)\n",
        "axes[1].set_title('Hyperparameter Importance', fontsize=14, weight='bold')\n",
        "axes[1].grid(alpha=0.3, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7Y4aK0vzb-U"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BLOK 9: FINAL MODEL TRAINING\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BLOK 9: FINAL MODEL TRAINING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Próba wczytania z checkpointu\n",
        "training_checkpoint = load_checkpoint('trained_model')\n",
        "\n",
        "if training_checkpoint:\n",
        "    model_final = TransferLearningModel(num_classes=2, freeze_backbone=True,\n",
        "                                       dropout=training_checkpoint['dropout']).to(device)\n",
        "    model_final.load_state_dict(training_checkpoint['model_state'])\n",
        "    train_losses = training_checkpoint['train_losses']\n",
        "    val_losses = training_checkpoint['val_losses']\n",
        "    train_accs = training_checkpoint['train_accs']\n",
        "    val_accs = training_checkpoint['val_accs']\n",
        "    best_val_acc = training_checkpoint['best_val_acc']\n",
        "    print(\"Model loaded from checkpoint\")\n",
        "else:\n",
        "    model_final = TransferLearningModel(num_classes=2, freeze_backbone=True,\n",
        "                                       dropout=best_params['dropout']).to(device)\n",
        "\n",
        "    if best_params['optimizer'] == 'Adam':\n",
        "        optimizer = optim.Adam(filter(lambda p: p.requires_grad, model_final.parameters()),\n",
        "                              lr=best_params['lr'])\n",
        "    else:\n",
        "        optimizer = optim.SGD(filter(lambda p: p.requires_grad, model_final.parameters()),\n",
        "                             lr=best_params['lr'], momentum=0.9)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max',\n",
        "                                                     factor=0.5, patience=3)\n",
        "\n",
        "    NUM_EPOCHS = 5\n",
        "    best_val_acc = 0.0\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accs, val_accs = [], []\n",
        "\n",
        "    print(f\"Training for {NUM_EPOCHS} epochs...\")\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        model_final.train()\n",
        "        running_loss, correct_train, total_train = 0.0, 0, 0\n",
        "\n",
        "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS}')\n",
        "        for images, labels in train_pbar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            labels = torch.tensor([class_mapping[int(l)] for l in labels.cpu()]).to(device).squeeze()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model_final(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = correct_train / total_train\n",
        "\n",
        "        model_final.eval()\n",
        "        running_val_loss, correct_val, total_val = 0.0, 0, 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                labels = torch.tensor([class_mapping[int(l)] for l in labels.cpu()]).to(device).squeeze()\n",
        "\n",
        "                outputs = model_final(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                running_val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total_val += labels.size(0)\n",
        "                correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss = running_val_loss / len(val_loader)\n",
        "        val_acc = correct_val / total_val\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        scheduler.step(val_acc)\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model_final.state_dict(), 'best_model_octmnist.pth')\n",
        "\n",
        "        print(f'Epoch {epoch+1}: Train Acc={train_acc:.4f} | Val Acc={val_acc:.4f}')\n",
        "\n",
        "    save_checkpoint('trained_model', {\n",
        "        'model_state': model_final.state_dict(),\n",
        "        'dropout': best_params['dropout'],\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses,\n",
        "        'train_accs': train_accs,\n",
        "        'val_accs': val_accs,\n",
        "        'best_val_acc': best_val_acc\n",
        "    })\n",
        "\n",
        "    print(f\"\\nTraining complete! Best Val Acc: {best_val_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_XAPQ88zwgr"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BLOK 10: WIZUALIZACJA TRENINGU\n",
        "# ============================================================================\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "axes[0].plot(train_losses, label='Train', linewidth=2, marker='o', markersize=4)\n",
        "axes[0].plot(val_losses, label='Val', linewidth=2, marker='s', markersize=4)\n",
        "axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "axes[0].set_ylabel('Loss', fontsize=12)\n",
        "axes[0].set_title('Training & Validation Loss', fontsize=14, weight='bold')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "axes[1].plot(train_accs, label='Train', linewidth=2, marker='o', markersize=4)\n",
        "axes[1].plot(val_accs, label='Val', linewidth=2, marker='s', markersize=4)\n",
        "axes[1].axhline(y=best_val_acc, color='red', linestyle='--', linewidth=2,\n",
        "                label=f'Best: {best_val_acc:.4f}')\n",
        "axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
        "axes[1].set_title('Training & Validation Accuracy', fontsize=14, weight='bold')\n",
        "axes[1].legend()\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gv-YurlDz3IT"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BLOK 11: EWALUACJA NA ZBIORZE TESTOWYM\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BLOK 11: TEST SET EVALUATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "eval_checkpoint = load_checkpoint('evaluation_results')\n",
        "\n",
        "if eval_checkpoint:\n",
        "    all_preds = eval_checkpoint['all_preds']\n",
        "    all_labels = eval_checkpoint['all_labels']\n",
        "    all_probs = eval_checkpoint['all_probs']\n",
        "    test_acc = eval_checkpoint['test_acc']\n",
        "    print(\"Evaluation results loaded from checkpoint\")\n",
        "else:\n",
        "    model_final.load_state_dict(torch.load('best_model_octmnist.pth'))\n",
        "    model_final.eval()\n",
        "\n",
        "    all_preds, all_labels, all_probs = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc='Evaluating'):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            labels = torch.tensor([class_mapping[int(l)] for l in labels.cpu()]).to(device).squeeze()\n",
        "\n",
        "            outputs = model_final(images)\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_probs = np.array(all_probs)\n",
        "    test_acc = (all_preds == all_labels).sum() / len(all_labels)\n",
        "\n",
        "    save_checkpoint('evaluation_results', {\n",
        "        'all_preds': all_preds,\n",
        "        'all_labels': all_labels,\n",
        "        'all_probs': all_probs,\n",
        "        'test_acc': test_acc\n",
        "    })\n",
        "\n",
        "print(f\"\\nTest Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-g-soK-qz_Rc"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BLOK 12: CLASSIFICATION REPORT\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds,\n",
        "                          target_names=['CNV', 'NORMAL'], digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uc2BZQsb0Aom"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BLOK 13: CONFUSION MATRIX\n",
        "# ============================================================================\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['CNV', 'NORMAL'],\n",
        "            yticklabels=['CNV', 'NORMAL'])\n",
        "plt.title('Confusion Matrix', fontsize=14, weight='bold')\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j + 0.5, i + 0.7, f'({cm[i,j]/cm[i].sum()*100:.1f}%)',\n",
        "                ha='center', va='center',\n",
        "                color='white' if cm[i, j] > cm.max() / 2 else 'black')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fss4UXlk0Lb5"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BLOK 14: ROC CURVE\n",
        "# ============================================================================\n",
        "\n",
        "fpr, tpr, _ = roc_curve(all_labels, all_probs[:, 1])\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, linewidth=2, label=f'AUC = {roc_auc:.4f}', color='darkorange')\n",
        "plt.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random')\n",
        "plt.xlabel('False Positive Rate', fontsize=12)\n",
        "plt.ylabel('True Positive Rate', fontsize=12)\n",
        "plt.title('ROC Curve', fontsize=14, weight='bold')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRW6MgA-0Sjb"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BLOK 15: PRECISION-RECALL CURVE\n",
        "# ============================================================================\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(all_labels, all_probs[:, 1])\n",
        "pr_auc = auc(recall, precision)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, linewidth=2, label=f'AUC = {pr_auc:.4f}', color='green')\n",
        "plt.xlabel('Recall', fontsize=12)\n",
        "plt.ylabel('Precision', fontsize=12)\n",
        "plt.title('Precision-Recall Curve', fontsize=14, weight='bold')\n",
        "plt.legend(loc='lower left')\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJJmKPH50Z6W"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BLOK 16: FINAL SUMMARY\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL RESULTS SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nModel: ResNet18 Transfer Learning\")\n",
        "print(f\"Task: Binary Classification (CNV vs NORMAL)\")\n",
        "print(f\"Best Val Accuracy: {best_val_acc:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "print(f\"PR AUC: {pr_auc:.4f}\")\n",
        "\n",
        "print(f\"\\nSaved checkpoints:\")\n",
        "print(f\"  - {CHECKPOINT_DIR}/datasets.pkl\")\n",
        "print(f\"  - {CHECKPOINT_DIR}/optuna_study.pkl\")\n",
        "print(f\"  - {CHECKPOINT_DIR}/trained_model.pkl\")\n",
        "print(f\"  - {CHECKPOINT_DIR}/evaluation_results.pkl\")\n",
        "print(f\"  - best_model_octmnist.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTFjExDq0qmt"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BLOK 17: ZAAWANSOWANA WYJAŚNIALNOŚĆ MODELU - DEFINICJE\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BLOK 17: MODEL INTERPRETABILITY & EXPLAINABILITY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "import cv2\n",
        "from scipy.ndimage import gaussian_filter\n",
        "\n",
        "# ============================================================================\n",
        "# 1. GRAD-CAM IMPLEMENTATION\n",
        "# ============================================================================\n",
        "\n",
        "class GradCAM:\n",
        "    def __init__(self, model, target_layer):\n",
        "        self.model = model\n",
        "        self.target_layer = target_layer\n",
        "        self.gradients = None\n",
        "        self.activations = None\n",
        "\n",
        "        self.target_layer.register_forward_hook(self.save_activation)\n",
        "        self.target_layer.register_full_backward_hook(self.save_gradient)\n",
        "\n",
        "    def save_activation(self, module, input, output):\n",
        "        self.activations = output.detach()\n",
        "\n",
        "    def save_gradient(self, module, grad_input, grad_output):\n",
        "        self.gradients = grad_output[0].detach()\n",
        "\n",
        "    def generate_cam(self, input_image, target_class=None):\n",
        "        self.model.eval()\n",
        "\n",
        "        output = self.model(input_image)\n",
        "\n",
        "        if target_class is None:\n",
        "            target_class = output.argmax(dim=1).item()\n",
        "\n",
        "        self.model.zero_grad()\n",
        "        class_score = output[0, target_class]\n",
        "        class_score.backward()\n",
        "\n",
        "        weights = torch.mean(self.gradients, dim=[2, 3], keepdim=True)\n",
        "        cam = torch.sum(weights * self.activations, dim=1).squeeze()\n",
        "        cam = F.relu(cam)\n",
        "\n",
        "        cam = cam - cam.min()\n",
        "        if cam.max() > 0:\n",
        "            cam = cam / cam.max()\n",
        "\n",
        "        cam = cam.cpu().numpy()\n",
        "        cam = cv2.resize(cam, (256, 256))\n",
        "\n",
        "        return cam, target_class\n",
        "\n",
        "# ============================================================================\n",
        "# 2. SALIENCY MAPS\n",
        "# ============================================================================\n",
        "\n",
        "def generate_saliency_map(model, input_image, target_class=None):\n",
        "    model.eval()\n",
        "    input_image = input_image.clone().requires_grad_(True)\n",
        "\n",
        "    output = model(input_image)\n",
        "\n",
        "    if target_class is None:\n",
        "        target_class = output.argmax(dim=1).item()\n",
        "\n",
        "    model.zero_grad()\n",
        "    class_score = output[0, target_class]\n",
        "    class_score.backward()\n",
        "\n",
        "    saliency = input_image.grad.data.abs().squeeze()\n",
        "    saliency = saliency.cpu().numpy()\n",
        "\n",
        "    saliency = (saliency - saliency.min()) / (saliency.max() - saliency.min() + 1e-8)\n",
        "\n",
        "    return saliency, target_class\n",
        "\n",
        "# ============================================================================\n",
        "# 3. INTEGRATED GRADIENTS\n",
        "# ============================================================================\n",
        "\n",
        "def integrated_gradients(model, input_image, target_class=None, steps=50):\n",
        "    model.eval()\n",
        "\n",
        "    baseline = torch.zeros_like(input_image)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_image)\n",
        "\n",
        "    if target_class is None:\n",
        "        target_class = output.argmax(dim=1).item()\n",
        "\n",
        "    scaled_inputs = [baseline + (float(i) / steps) * (input_image - baseline)\n",
        "                     for i in range(steps + 1)]\n",
        "\n",
        "    grads = []\n",
        "    for scaled_input in scaled_inputs:\n",
        "        scaled_input = scaled_input.requires_grad_(True)\n",
        "        output = model(scaled_input)\n",
        "\n",
        "        model.zero_grad()\n",
        "        class_score = output[0, target_class]\n",
        "        class_score.backward()\n",
        "\n",
        "        grads.append(scaled_input.grad.data.clone())\n",
        "\n",
        "    avg_grads = torch.stack(grads).mean(dim=0)\n",
        "\n",
        "    integrated_grad = (input_image - baseline) * avg_grads\n",
        "    integrated_grad = integrated_grad.squeeze().abs().cpu().numpy()\n",
        "\n",
        "    integrated_grad = (integrated_grad - integrated_grad.min()) / \\\n",
        "                      (integrated_grad.max() - integrated_grad.min() + 1e-8)\n",
        "\n",
        "    return integrated_grad, target_class\n",
        "\n",
        "# ============================================================================\n",
        "# 4. OCCLUSION SENSITIVITY\n",
        "# ============================================================================\n",
        "\n",
        "def occlusion_sensitivity(model, input_image, target_class=None,\n",
        "                          window_size=32, stride=16):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        original_output = model(input_image)\n",
        "\n",
        "    if target_class is None:\n",
        "        target_class = original_output.argmax(dim=1).item()\n",
        "\n",
        "    original_prob = torch.softmax(original_output, dim=1)[0, target_class].item()\n",
        "\n",
        "    h, w = input_image.shape[2], input_image.shape[3]\n",
        "    sensitivity_map = np.zeros((h, w))\n",
        "\n",
        "    for y in range(0, h - window_size, stride):\n",
        "        for x in range(0, w - window_size, stride):\n",
        "            occluded = input_image.clone()\n",
        "            occluded[:, :, y:y+window_size, x:x+window_size] = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                output = model(occluded)\n",
        "                prob = torch.softmax(output, dim=1)[0, target_class].item()\n",
        "\n",
        "            importance = original_prob - prob\n",
        "            sensitivity_map[y:y+window_size, x:x+window_size] += importance\n",
        "\n",
        "    sensitivity_map = (sensitivity_map - sensitivity_map.min()) / \\\n",
        "                      (sensitivity_map.max() - sensitivity_map.min() + 1e-8)\n",
        "\n",
        "    sensitivity_map = gaussian_filter(sensitivity_map, sigma=3)\n",
        "\n",
        "    return sensitivity_map, target_class\n",
        "\n",
        "# ============================================================================\n",
        "# 5. FUNKCJE POMOCNICZE - WIZUALIZACJA\n",
        "# ============================================================================\n",
        "\n",
        "def overlay_heatmap(image, heatmap, alpha=0.4, colormap=cv2.COLORMAP_JET):\n",
        "\n",
        "    if isinstance(image, torch.Tensor):\n",
        "        image = image.cpu().squeeze().numpy()\n",
        "\n",
        "    image = (image * 0.5 + 0.5).clip(0, 1)\n",
        "\n",
        "    heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap), colormap)\n",
        "    heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB) / 255.0\n",
        "\n",
        "    image_rgb = np.stack([image] * 3, axis=-1)\n",
        "\n",
        "    overlayed = (1 - alpha) * image_rgb + alpha * heatmap_colored\n",
        "\n",
        "    return overlayed\n",
        "\n",
        "def visualize_all_methods(model, image, label, prediction, prob,\n",
        "                         grad_cam, sample_idx):\n",
        "\n",
        "    device = next(model.parameters()).device\n",
        "    img_tensor = image.unsqueeze(0).to(device)\n",
        "\n",
        "    print(f\"  Generating explanations for sample {sample_idx}...\")\n",
        "\n",
        "    cam, pred_class = grad_cam.generate_cam(img_tensor, prediction)\n",
        "    saliency, _ = generate_saliency_map(model, img_tensor, prediction)\n",
        "    ig, _ = integrated_gradients(model, img_tensor, prediction, steps=30)\n",
        "    occl, _ = occlusion_sensitivity(model, img_tensor, prediction,\n",
        "                                    window_size=24, stride=12)\n",
        "\n",
        "    img_np = (image.cpu().squeeze().numpy() * 0.5 + 0.5).clip(0, 1)\n",
        "\n",
        "    is_correct = (label == prediction)\n",
        "    status = \"CORRECT\" if is_correct else \"WRONG\"\n",
        "    status_color = 'green' if is_correct else 'red'\n",
        "\n",
        "    class_names = ['CNV', 'NORMAL']\n",
        "\n",
        "    fig = plt.figure(figsize=(20, 4))\n",
        "    gs = GridSpec(1, 6, figure=fig, wspace=0.3)\n",
        "\n",
        "    ax1 = fig.add_subplot(gs[0, 0])\n",
        "    ax1.imshow(img_np, cmap='gray')\n",
        "    ax1.set_title(f\"Original\\nTrue: {class_names[label]}\",\n",
        "                  fontsize=10, weight='bold')\n",
        "    ax1.axis('off')\n",
        "\n",
        "    ax2 = fig.add_subplot(gs[0, 1])\n",
        "    overlay = overlay_heatmap(image, cam, alpha=0.5)\n",
        "    ax2.imshow(overlay)\n",
        "    ax2.set_title(\"Grad-CAM\\n(Where model looks)\",\n",
        "                  fontsize=10, weight='bold')\n",
        "    ax2.axis('off')\n",
        "\n",
        "    ax3 = fig.add_subplot(gs[0, 2])\n",
        "    ax3.imshow(saliency, cmap='hot')\n",
        "    ax3.set_title(\"Saliency Map\\n(Important pixels)\",\n",
        "                  fontsize=10, weight='bold')\n",
        "    ax3.axis('off')\n",
        "\n",
        "    ax4 = fig.add_subplot(gs[0, 3])\n",
        "    ax4.imshow(ig, cmap='hot')\n",
        "    ax4.set_title(\"Integrated Gradients\\n(Stable attribution)\",\n",
        "                  fontsize=10, weight='bold')\n",
        "    ax4.axis('off')\n",
        "\n",
        "    ax5 = fig.add_subplot(gs[0, 4])\n",
        "    ax5.imshow(occl, cmap='hot')\n",
        "    ax5.set_title(\"Occlusion Sensitivity\\n(Critical regions)\",\n",
        "                  fontsize=10, weight='bold')\n",
        "    ax5.axis('off')\n",
        "\n",
        "    ax6 = fig.add_subplot(gs[0, 5])\n",
        "    ax6.axis('off')\n",
        "\n",
        "    info_text = f\"{status}\\n\\n\"\n",
        "    info_text += f\"Pred: {class_names[prediction]}\\n\"\n",
        "    info_text += f\"Conf: {prob[prediction]:.1%}\\n\\n\"\n",
        "    info_text += f\"Probabilities:\\n\"\n",
        "    info_text += f\"  CNV:    {prob[0]:.1%}\\n\"\n",
        "    info_text += f\"  NORMAL: {prob[1]:.1%}\"\n",
        "\n",
        "    ax6.text(0.1, 0.5, info_text, fontsize=10,\n",
        "             verticalalignment='center',\n",
        "             family='monospace',\n",
        "             bbox=dict(boxstyle='round', facecolor=status_color, alpha=0.2))\n",
        "\n",
        "    plt.suptitle(f\"Sample #{sample_idx} - Complete Explainability Analysis\",\n",
        "                 fontsize=14, weight='bold', y=0.98)\n",
        "\n",
        "    return fig\n",
        "\n",
        "print(\"Explainability functions defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Q2bdfB92KOI"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BLOK 17A: NAJLEPSZE PRZYPADKI - HIGH CONFIDENCE + CORRECT\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BLOK 17A: BEST CASES ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\nInitializing explainability tools...\")\n",
        "\n",
        "model_final.load_state_dict(torch.load('best_model_octmnist.pth'))\n",
        "model_final.eval()\n",
        "\n",
        "target_layer = model_final.backbone.layer4[-1].conv2\n",
        "grad_cam = GradCAM(model_final, target_layer)\n",
        "\n",
        "print(\"Grad-CAM initialized\")\n",
        "print(\"Saliency Maps ready\")\n",
        "print(\"Integrated Gradients ready\")\n",
        "print(\"Occlusion Sensitivity ready\")\n",
        "\n",
        "print(\"\\nCollecting test set data...\")\n",
        "\n",
        "all_test_images = []\n",
        "all_test_labels_full = []\n",
        "all_test_preds_full = []\n",
        "all_test_probs_full = []\n",
        "\n",
        "model_final.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = torch.tensor([class_mapping[int(l)] for l in labels.cpu()]).to(device)\n",
        "\n",
        "        outputs = model_final(images)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        all_test_images.extend(images.cpu())\n",
        "        all_test_labels_full.extend(labels.cpu())\n",
        "        all_test_preds_full.extend(predicted.cpu())\n",
        "        all_test_probs_full.extend(probs.cpu())\n",
        "\n",
        "all_test_images = torch.stack(all_test_images)\n",
        "all_test_labels_full = torch.tensor(all_test_labels_full)\n",
        "all_test_preds_full = torch.tensor(all_test_preds_full)\n",
        "all_test_probs_full = torch.stack(all_test_probs_full)\n",
        "\n",
        "print(f\"Collected {len(all_test_images)} test samples\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"A. BEST CASES (High Confidence + Correct)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "correct_mask = (all_test_labels_full == all_test_preds_full)\n",
        "correct_indices = torch.where(correct_mask)[0]\n",
        "\n",
        "confidences = all_test_probs_full[range(len(all_test_preds_full)), all_test_preds_full]\n",
        "correct_confidences = confidences[correct_mask]\n",
        "\n",
        "print(f\"\\nStatistics for correct predictions:\")\n",
        "print(f\"  Total correct:           {correct_mask.sum().item()} / {len(all_test_images)}\")\n",
        "print(f\"  Mean confidence:         {correct_confidences.mean():.4f}\")\n",
        "print(f\"  High confidence (>95%):  {(correct_confidences > 0.95).sum().item()} samples\")\n",
        "print(f\"  High confidence (>90%):  {(correct_confidences > 0.90).sum().item()} samples\")\n",
        "\n",
        "sorted_correct = correct_indices[correct_confidences.argsort(descending=True)]\n",
        "\n",
        "print(f\"\\nAnalyzing TOP 3 best predictions...\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "for i, idx in enumerate(sorted_correct[:3]):\n",
        "    idx = idx.item()\n",
        "\n",
        "    true_label = all_test_labels_full[idx].item()\n",
        "    pred_label = all_test_preds_full[idx].item()\n",
        "    confidence = confidences[idx].item()\n",
        "    class_names = ['CNV', 'NORMAL']\n",
        "\n",
        "    print(f\"\\n{'-'*70}\")\n",
        "    print(f\"BEST CASE #{i+1} - Sample index: {idx}\")\n",
        "    print(f\"{'-'*70}\")\n",
        "    print(f\"  True Label:     {class_names[true_label]}\")\n",
        "    print(f\"  Prediction:     {class_names[pred_label]}\")\n",
        "    print(f\"  Confidence:     {confidence:.4f} ({confidence*100:.2f}%)\")\n",
        "    print(f\"  CNV prob:       {all_test_probs_full[idx][0]:.4f}\")\n",
        "    print(f\"  NORMAL prob:    {all_test_probs_full[idx][1]:.4f}\")\n",
        "\n",
        "    fig = visualize_all_methods(\n",
        "        model_final,\n",
        "        all_test_images[idx],\n",
        "        all_test_labels_full[idx].item(),\n",
        "        all_test_preds_full[idx].item(),\n",
        "        all_test_probs_full[idx].numpy(),\n",
        "        grad_cam,\n",
        "        idx\n",
        "    )\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"PER-CLASS ANALYSIS OF BEST CASES\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "for class_idx, class_name in enumerate(['CNV', 'NORMAL']):\n",
        "    class_correct_mask = (all_test_labels_full == class_idx) & correct_mask\n",
        "    class_correct_indices = torch.where(class_correct_mask)[0]\n",
        "    class_confidences = confidences[class_correct_mask]\n",
        "\n",
        "    if len(class_confidences) > 0:\n",
        "        print(f\"\\n{class_name}:\")\n",
        "        print(f\"  Correct predictions:     {len(class_confidences)}\")\n",
        "        print(f\"  Mean confidence:         {class_confidences.mean():.4f}\")\n",
        "        print(f\"  Max confidence:          {class_confidences.max():.4f}\")\n",
        "        print(f\"  Min confidence:          {class_confidences.min():.4f}\")\n",
        "        print(f\"  Confidence > 99%:        {(class_confidences > 0.99).sum().item()} samples\")\n",
        "\n",
        "print(\"\\nBest cases analysis complete!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfqCX4dB2UsP"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BLOK 17B: BŁĘDNE KLASYFIKACJE - ERROR ANALYSIS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BLOK 17B: MISCLASSIFIED CASES ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "error_mask = ~correct_mask\n",
        "error_indices = torch.where(error_mask)[0]\n",
        "\n",
        "total_errors = error_mask.sum().item()\n",
        "error_rate = total_errors / len(all_test_images) * 100\n",
        "\n",
        "print(f\"\\nError Statistics:\")\n",
        "print(f\"  Total errors:            {total_errors} / {len(all_test_images)}\")\n",
        "print(f\"  Error rate:              {error_rate:.2f}%\")\n",
        "print(f\"  Correct predictions:     {correct_mask.sum().item()} ({(100-error_rate):.2f}%)\")\n",
        "\n",
        "if total_errors > 0:\n",
        "    error_confidences = confidences[error_mask]\n",
        "\n",
        "    print(f\"\\nError Confidence Analysis:\")\n",
        "    print(f\"  Mean confidence (errors):    {error_confidences.mean():.4f}\")\n",
        "    print(f\"  Max confidence (error):      {error_confidences.max():.4f}\")\n",
        "    print(f\"  Min confidence (error):      {error_confidences.min():.4f}\")\n",
        "    print(f\"  Errors with conf > 80%:      {(error_confidences > 0.80).sum().item()} samples\")\n",
        "    print(f\"  Errors with conf > 70%:      {(error_confidences > 0.70).sum().item()} samples\")\n",
        "\n",
        "    print(f\"\\nError Type Breakdown:\")\n",
        "\n",
        "    false_positives = (all_test_labels_full == 1) & (all_test_preds_full == 0)\n",
        "    fp_count = false_positives.sum().item()\n",
        "\n",
        "    false_negatives = (all_test_labels_full == 0) & (all_test_preds_full == 1)\n",
        "    fn_count = false_negatives.sum().item()\n",
        "\n",
        "    print(f\"  False Positives (NORMAL->CNV): {fp_count} ({fp_count/total_errors*100:.1f}% of errors)\")\n",
        "    print(f\"  False Negatives (CNV->NORMAL): {fn_count} ({fn_count/total_errors*100:.1f}% of errors)\")\n",
        "\n",
        "    cnv_total = (all_test_labels_full == 0).sum().item()\n",
        "    normal_total = (all_test_labels_full == 1).sum().item()\n",
        "\n",
        "    print(f\"\\nClinical Impact:\")\n",
        "    print(f\"  CNV missed rate:         {fn_count}/{cnv_total} = {fn_count/cnv_total*100:.2f}%\")\n",
        "    print(f\"  False alarm rate:        {fp_count}/{normal_total} = {fp_count/normal_total*100:.2f}%\")\n",
        "\n",
        "    sorted_errors = error_indices[error_confidences.argsort(descending=True)]\n",
        "\n",
        "    num_errors_to_show = min(3, len(sorted_errors))\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"ANALYZING {num_errors_to_show} MOST CONFIDENT MISCLASSIFICATIONS\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    for i, idx in enumerate(sorted_errors[:num_errors_to_show]):\n",
        "        idx = idx.item()\n",
        "\n",
        "        true_label = all_test_labels_full[idx].item()\n",
        "        pred_label = all_test_preds_full[idx].item()\n",
        "        confidence = confidences[idx].item()\n",
        "        class_names = ['CNV', 'NORMAL']\n",
        "\n",
        "        if true_label == 0 and pred_label == 1:\n",
        "            error_type = \"FALSE NEGATIVE (CNV missed)\"\n",
        "            severity = \"HIGH RISK\"\n",
        "        else:\n",
        "            error_type = \"FALSE POSITIVE (False alarm)\"\n",
        "            severity = \"MEDIUM RISK\"\n",
        "\n",
        "        print(f\"\\n{'-'*70}\")\n",
        "        print(f\"ERROR CASE #{i+1} - Sample index: {idx}\")\n",
        "        print(f\"{'-'*70}\")\n",
        "        print(f\"  Error Type:     {error_type}\")\n",
        "        print(f\"  Severity:       {severity}\")\n",
        "        print(f\"  True Label:     {class_names[true_label]}\")\n",
        "        print(f\"  Prediction:     {class_names[pred_label]}\")\n",
        "        print(f\"  Confidence:     {confidence:.4f} ({confidence*100:.2f}%)\")\n",
        "        print(f\"  CNV prob:       {all_test_probs_full[idx][0]:.4f}\")\n",
        "        print(f\"  NORMAL prob:    {all_test_probs_full[idx][1]:.4f}\")\n",
        "\n",
        "        fig = visualize_all_methods(\n",
        "            model_final,\n",
        "            all_test_images[idx],\n",
        "            all_test_labels_full[idx].item(),\n",
        "            all_test_preds_full[idx].item(),\n",
        "            all_test_probs_full[idx].numpy(),\n",
        "            grad_cam,\n",
        "            idx\n",
        "        )\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "else:\n",
        "    print(\"\\nPERFECT ACCURACY!\")\n",
        "    print(\"No misclassified samples in test set (100% accuracy)\")\n",
        "    print(\"This is exceptional performance for medical imaging!\")\n",
        "\n",
        "print(\"\\nError analysis complete!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eA-Th3bb2gWL"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BLOK 17C: TRUDNE PRZYPADKI - LOW CONFIDENCE BUT CORRECT\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"BLOK 17C: UNCERTAIN CASES ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "UNCERTAINTY_THRESHOLD = 0.70\n",
        "\n",
        "low_conf_correct = correct_indices[correct_confidences < UNCERTAINTY_THRESHOLD]\n",
        "low_conf_values = confidences[low_conf_correct]\n",
        "\n",
        "print(f\"\\nUncertainty Statistics:\")\n",
        "print(f\"  Uncertainty threshold:       {UNCERTAINTY_THRESHOLD:.2f} ({UNCERTAINTY_THRESHOLD*100:.0f}%)\")\n",
        "print(f\"  Uncertain cases (correct):   {len(low_conf_correct)} / {len(correct_indices)}\")\n",
        "print(f\"  Percentage of correct:       {len(low_conf_correct)/len(correct_indices)*100:.2f}%\")\n",
        "print(f\"  Percentage of total:         {len(low_conf_correct)/len(all_test_images)*100:.2f}%\")\n",
        "\n",
        "if len(low_conf_correct) > 0:\n",
        "    print(f\"\\nConfidence Distribution (Uncertain Cases):\")\n",
        "    print(f\"  Mean confidence:         {low_conf_values.mean():.4f}\")\n",
        "    print(f\"  Max confidence:          {low_conf_values.max():.4f}\")\n",
        "    print(f\"  Min confidence:          {low_conf_values.min():.4f}\")\n",
        "    print(f\"  Cases 60-70% conf:       {((low_conf_values >= 0.60) & (low_conf_values < 0.70)).sum().item()}\")\n",
        "    print(f\"  Cases 50-60% conf:       {((low_conf_values >= 0.50) & (low_conf_values < 0.60)).sum().item()}\")\n",
        "    print(f\"  Cases <50% conf:         {(low_conf_values < 0.50).sum().item()}\")\n",
        "\n",
        "    print(f\"\\nPer-Class Uncertainty Breakdown:\")\n",
        "\n",
        "    for class_idx, class_name in enumerate(['CNV', 'NORMAL']):\n",
        "        class_uncertain_mask = (all_test_labels_full[low_conf_correct] == class_idx)\n",
        "        class_uncertain_count = class_uncertain_mask.sum().item()\n",
        "\n",
        "        if class_uncertain_count > 0:\n",
        "            class_uncertain_confs = low_conf_values[class_uncertain_mask]\n",
        "            print(f\"\\n  {class_name}:\")\n",
        "            print(f\"    Uncertain cases:       {class_uncertain_count}\")\n",
        "            print(f\"    Mean confidence:       {class_uncertain_confs.mean():.4f}\")\n",
        "            print(f\"    Min confidence:        {class_uncertain_confs.min():.4f}\")\n",
        "\n",
        "    sorted_uncertain = low_conf_correct[low_conf_values.argsort()]\n",
        "\n",
        "    num_uncertain = min(3, len(sorted_uncertain))\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"ANALYZING {num_uncertain} MOST UNCERTAIN PREDICTIONS\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    for i, idx in enumerate(sorted_uncertain[:num_uncertain]):\n",
        "        idx = idx.item()\n",
        "\n",
        "        true_label = all_test_labels_full[idx].item()\n",
        "        pred_label = all_test_preds_full[idx].item()\n",
        "        confidence = confidences[idx].item()\n",
        "        class_names = ['CNV', 'NORMAL']\n",
        "\n",
        "        cnv_prob = all_test_probs_full[idx][0].item()\n",
        "        normal_prob = all_test_probs_full[idx][1].item()\n",
        "        prob_diff = abs(cnv_prob - normal_prob)\n",
        "\n",
        "        if prob_diff < 0.10:\n",
        "            uncertainty_level = \"VERY HIGH (near 50-50)\"\n",
        "        elif prob_diff < 0.20:\n",
        "            uncertainty_level = \"HIGH (close decision)\"\n",
        "        else:\n",
        "            uncertainty_level = \"MODERATE (borderline)\"\n",
        "\n",
        "        print(f\"\\n{'-'*70}\")\n",
        "        print(f\"UNCERTAIN CASE #{i+1} - Sample index: {idx}\")\n",
        "        print(f\"{'-'*70}\")\n",
        "        print(f\"  Uncertainty Level:  {uncertainty_level}\")\n",
        "        print(f\"  True Label:         {class_names[true_label]}\")\n",
        "        print(f\"  Prediction:         {class_names[pred_label]} (CORRECT)\")\n",
        "        print(f\"  Confidence:         {confidence:.4f} ({confidence*100:.2f}%)\")\n",
        "        print(f\"  CNV prob:           {cnv_prob:.4f}\")\n",
        "        print(f\"  NORMAL prob:        {normal_prob:.4f}\")\n",
        "        print(f\"  Probability diff:   {prob_diff:.4f}\")\n",
        "\n",
        "        fig = visualize_all_methods(\n",
        "            model_final,\n",
        "            all_test_images[idx],\n",
        "            all_test_labels_full[idx].item(),\n",
        "            all_test_preds_full[idx].item(),\n",
        "            all_test_probs_full[idx].numpy(),\n",
        "            grad_cam,\n",
        "            idx\n",
        "        )\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "else:\n",
        "    print(\"\\nNO UNCERTAIN CASES FOUND!\")\n",
        "    print(f\"All correct predictions have confidence >= {UNCERTAINTY_THRESHOLD*100:.0f}%\")\n",
        "    print(\"This indicates excellent model calibration and decision certainty.\")\n",
        "\n",
        "print(\"\\nUncertain cases analysis complete!\")\n",
        "print(\"=\"*70)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}